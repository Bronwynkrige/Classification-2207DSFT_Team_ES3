{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ddcc8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: unknown command \"install¬†clean-text\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip¬†install¬†clean-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "92bb7a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: clean-text in c:\\users\\sweet pea\\anaconda3\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: emoji<2.0.0,>=1.0.0 in c:\\users\\sweet pea\\anaconda3\\lib\\site-packages (from clean-text) (1.7.0)\n",
      "Requirement already satisfied: ftfy<7.0,>=6.0 in c:\\users\\sweet pea\\anaconda3\\lib\\site-packages (from clean-text) (6.1.1)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in c:\\users\\sweet pea\\anaconda3\\lib\\site-packages (from ftfy<7.0,>=6.0->clean-text) (0.2.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install clean-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5d9c4842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this sample text contains laughing emojis\n"
     ]
    }
   ],
   "source": [
    "#import clean function\n",
    "from cleantext import clean\n",
    "\n",
    "#provide string with emojis\n",
    "text = \"This sample text contains laughing emojis üòÄ üòÉ üòÑ üòÅ üòÜ üòÖ üòÇ ü§£\"\n",
    "#\n",
    "#print text after removing the emojis from it\n",
    "print(clean(text, no_emoji=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db02fecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15814</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @ezlusztig: They took down the material on ...</td>\n",
       "      <td>22001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15815</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @washingtonpost: How climate change could b...</td>\n",
       "      <td>17856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15816</th>\n",
       "      <td>0</td>\n",
       "      <td>notiven: RT: nytimesworld :What does Trump act...</td>\n",
       "      <td>384248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15817</th>\n",
       "      <td>-1</td>\n",
       "      <td>RT @sara8smiles: Hey liberals the climate chan...</td>\n",
       "      <td>819732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15818</th>\n",
       "      <td>0</td>\n",
       "      <td>RT @Chet_Cannon: .@kurteichenwald's 'climate c...</td>\n",
       "      <td>806319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15819 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment                                            message  tweetid\n",
       "0              1  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
       "1              1  It's not like we lack evidence of anthropogeni...   126103\n",
       "2              2  RT @RawStory: Researchers say we have three ye...   698562\n",
       "3              1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n",
       "4              1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954\n",
       "...          ...                                                ...      ...\n",
       "15814          1  RT @ezlusztig: They took down the material on ...    22001\n",
       "15815          2  RT @washingtonpost: How climate change could b...    17856\n",
       "15816          0  notiven: RT: nytimesworld :What does Trump act...   384248\n",
       "15817         -1  RT @sara8smiles: Hey liberals the climate chan...   819732\n",
       "15818          0  RT @Chet_Cannon: .@kurteichenwald's 'climate c...   806319\n",
       "\n",
       "[15819 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2dc940d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweetid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>625221</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126103</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698562</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573736</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466954</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22001</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @ezlusztig: They took down the material on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17856</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @washingtonpost: How climate change could b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384248</th>\n",
       "      <td>0</td>\n",
       "      <td>notiven: RT: nytimesworld :What does Trump act...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819732</th>\n",
       "      <td>-1</td>\n",
       "      <td>RT @sara8smiles: Hey liberals the climate chan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806319</th>\n",
       "      <td>0</td>\n",
       "      <td>RT @Chet_Cannon: .@kurteichenwald's 'climate c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15819 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment                                            message\n",
       "tweetid                                                              \n",
       "625221           1  PolySciMajor EPA chief doesn't think carbon di...\n",
       "126103           1  It's not like we lack evidence of anthropogeni...\n",
       "698562           2  RT @RawStory: Researchers say we have three ye...\n",
       "573736           1  #TodayinMaker# WIRED : 2016 was a pivotal year...\n",
       "466954           1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...\n",
       "...            ...                                                ...\n",
       "22001            1  RT @ezlusztig: They took down the material on ...\n",
       "17856            2  RT @washingtonpost: How climate change could b...\n",
       "384248           0  notiven: RT: nytimesworld :What does Trump act...\n",
       "819732          -1  RT @sara8smiles: Hey liberals the climate chan...\n",
       "806319           0  RT @Chet_Cannon: .@kurteichenwald's 'climate c...\n",
       "\n",
       "[15819 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"train.csv\", index_col = \"tweetid\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2afc2e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweetid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>625221</th>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126103</th>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698562</th>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   message  sentiment\n",
       "tweetid                                                              \n",
       "625221   PolySciMajor EPA chief doesn't think carbon di...          1\n",
       "126103   It's not like we lack evidence of anthropogeni...          1\n",
       "698562   RT @RawStory: Researchers say we have three ye...          2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rearrange the columns for clarity\n",
    "data_sorted = data[[\"message\", \"sentiment\"]]\n",
    "data_sorted.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40df57e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweetid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>625221</th>\n",
       "      <td>polyscimajor epa chief doesn't think carbon di...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126103</th>\n",
       "      <td>it's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698562</th>\n",
       "      <td>rt @rawstory: researchers say we have three ye...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   message  sentiment\n",
       "tweetid                                                              \n",
       "625221   polyscimajor epa chief doesn't think carbon di...          1\n",
       "126103   it's not like we lack evidence of anthropogeni...          1\n",
       "698562   rt @rawstory: researchers say we have three ye...          2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make everything lower case\n",
    "'''\n",
    "Converting every letter into lowercase helps to understand better what the words \n",
    "state.\n",
    "'''\n",
    "data_sorted['message'] = data_sorted['message'].str.lower()\n",
    "data_sorted.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4797a18b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c94fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dced4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9b5484",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfd35e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#TodayinMaker# WIRED : 2016 was a pivotal year in the war on climate change url-web'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove web urls \n",
    "pattern_url = r'http[s]?://(?:[A-Za-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9A-Fa-f][0-9A-Fa-f]))+'\n",
    "subs_url = r'url-web'\n",
    "data['message'] = data['message'].replace(to_replace = pattern_url, value = subs_url, regex = True)\n",
    "data.iloc[3]['message']\n",
    "#df.iloc[0:5][['Age', 'Nationality']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "ae54100f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTING HYPOTHESIS \n",
    "# 1.first remove stopword\n",
    "# 2.remove contractions\n",
    "# 3.remove punctuations\n",
    "\n",
    "text = \"I wasn't in a good space, I'd like to go now üòÖ... Wow!!! Just the 4 of us. https://www.youtube.com/watch?v=B9ekChFUNOs&list=PLi8BQK-ZsrbguIeq8g1FvPe7A_X3DOYzz&index=58\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "afd81052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i wasn't in a good space, i'd like to go now üòÖ... wow!!! just the 4 of us. https://www.youtube.com/watch?v=b9ekchfunos&list=pli8bqk-zsrbguieq8g1fvpe7a_x3doyzz&index=58\""
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make everything lower case\n",
    "'''\n",
    "Converting every letter into lowercase helps to understand better what the words \n",
    "state.\n",
    "'''\n",
    "text = text.lower()\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11685641",
   "metadata": {},
   "source": [
    "#remove web urls \n",
    "pattern_url = r'http[s]?://(?:[A-Za-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9A-Fa-f][0-9A-Fa-f]))+'\n",
    "subs_url = r'url-web'\n",
    "text = text.replace(to_replace = pattern_url, value = subs_url, regex = True)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "69ac0163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i wasn't in a good space, i'd like to go now üòÖ... wow!!! just the 4 of us. \n"
     ]
    }
   ],
   "source": [
    "import cleantext\n",
    "\n",
    "text = cleantext.replace_urls(text, replace_with = \"url\")\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "e4e6470b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#str = 'Engineer123Discipline'\n",
    "#print(text.translate({ord(i): None for i in 'URL'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "ce50fa2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i wasn't in a good space, i'd like to go now üòÖ... wow!!! just the 4 of us. \n"
     ]
    }
   ],
   "source": [
    "text = text.replace('url', '') \n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "da9196da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i was not in a good space, i would like to go now üòÖ... wow!!! just the 4 of us.\n"
     ]
    }
   ],
   "source": [
    "#expand all existing contractions\n",
    "import contractions\n",
    "\n",
    "text = str(text)\n",
    "def expand_contractions(text):\n",
    "    return \" \".join([contractions.fix(c) for c in text.split()])\n",
    "\n",
    "text = expand_contractions(text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "8eaef635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i was not in a good space i would like to go now üòÖ wow just the 4 of us\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def remove_punctuation(post):\n",
    "    return ''.join([l for l in post if l not in string.punctuation])\n",
    "\n",
    "text = remove_punctuation(text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "bb25ee28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'was', 'not', 'in', 'a', 'good', 'space', 'i', 'would', 'like', 'to', 'go', 'now', 'üòÖ', 'wow', 'just', 'the', '4', 'of', 'us']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize, TreebankWordTokenizer\n",
    "text = word_tokenize(text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "8ab71e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['good', 'space', 'would', 'like', 'go', 'üòÖ', 'wow', '4', 'us']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "def remove_stop_words(tokens):    \n",
    "    return [t for t in tokens if t not in stopwords.words('english')]\n",
    "\n",
    "text = remove_stop_words(text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "159f2141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['good', 'space', 'would', 'like', 'go', '', 'wow', '4', 'us']\n"
     ]
    }
   ],
   "source": [
    "from cleantext import clean\n",
    "text = clean(text, no_emoji=True)\n",
    "             \n",
    "#print text after removing the emojis from it\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "54e1b55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['good', 'space', 'would', 'like', 'go', '', 'wow', '', 'us']\n"
     ]
    }
   ],
   "source": [
    "def remove_digits(post):\n",
    "    return ''.join([i for i in post if not i.isdigit()])\n",
    "\n",
    "text = remove_digits(text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "094baae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good space would like go  wow  us\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def remove_punctuation(post):\n",
    "    return ''.join([l for l in post if l not in string.punctuation])\n",
    "\n",
    "text = remove_punctuation(text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "c0983a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "cb6b4af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good space would like go wow us\n"
     ]
    }
   ],
   "source": [
    "def remove_extra_space(text):\n",
    "    return \" \".join(text.split())\n",
    "\n",
    "text = remove_extra_space(text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "61f43902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "b41de7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting advertools\n",
      "  Downloading advertools-0.13.2-py2.py3-none-any.whl (310 kB)\n",
      "Requirement already satisfied: scrapy>=2.5.0 in c:\\users\\sweet pea\\anaconda3\\lib\\site-packages (from advertools) (2.6.1)\n",
      "Requirement already satisfied: pyasn1>=0.4 in c:\\users\\sweet pea\\anaconda3\\lib\\site-packages (from advertools) (0.4.8)\n",
      "Collecting twython>=3.8.0\n",
      "  Downloading twython-3.9.1-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: pandas>=1.1.0 in c:\\users\\sweet pea\\anaconda3\\lib\\site-packages (from advertools) (1.4.2)\n",
      "Collecting pyarrow>=5.0.0\n",
      "  Downloading pyarrow-10.0.1-cp39-cp39-win_amd64.whl (20.3 MB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\sweet pea\\anaconda3\\lib\\site-packages (from pandas>=1.1.0->advertools) (1.21.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\sweet pea\\anaconda3\\lib\\site-packages (from pandas>=1.1.0->advertools) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sweet pea\\anaconda3\\lib\\site-packages (from pandas>=1.1.0->advertools) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sweet pea\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=1.1.0->advertools) (1.16.0)\n",
      "Requirement already satisfied: service-identity>=16.0.0 in c:\\users\\sweet pea\\anaconda3\\lib\\site-packages (from scrapy>=2.5.0->advertools) (18.1.0)\n",
      "Requirement already satisfied: itemloaders>=1.0.1 in c:\\users\\sweet pea\\anaconda3\\lib\\site-packages (from scrapy>=2.5.0->advertools) (1.0.4)\n",
      "Requirement already satisfied: queuelib>=1.4.2 in c:\\users\\sweet pea\\anaconda3\\lib\\site-packages (from scrapy>=2.5.0->advertools) (1.5.0)\n",
      "Requirement already satisfied: protego>=0.1.15 in c:\\users\\sweet pea\\anaconda3\\lib\\site-packages (from scrapy>=2.5.0->advertools) (0.1.16)\n",
      "Requirement already satisfied: itemadapter>=0.1.0 in c:\\users\\sweet pea\\anaconda3\\lib\\site-packages (from scrapy>=2.5.0->advertools) (0.3.0)\n",
      "Requirement already satisfied: cssselect>=0.9.1 in c:\\users\\sweet pea\\anaconda3\\lib\\site-packages (from scrapy>=2.5.0->advertools) (1.1.0)\n",
      "Requirement already satisfied: w3lib>=1.17.0 in c:\\users\\sweet pea\\anaconda3\\lib\\site-packages (from scrapy>=2.5.0->advertools) (1.21.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sweet pea\\anaconda3\\lib\\site-packages (from scrapy>=2.5.0->advertools) (61.2.0)\n",
      "Requirement already satisfied: lxml>=3.5.0 in c:\\users\\sweet pea\\anaconda3\\lib\\site-packages (from scrapy>=2.5.0->advertools) (4.8.0)\n",
      "Requirement already satisfied: tldextract in c:\\users\\sweet pea\\anaconda3\\lib\\site-packages (from scrapy>=2.5.0->advertools) (3.2.0)\n",
      "Requirement already satisfied: pyOpenSSL>=16.2.0 in c:\\users\\sweet pea\\anaconda3\\lib\\site-packages (from scrapy>=2.5.0->advertools) (21.0.0)\n",
      "Requirement already satisfied: cryptography>=2.0 in c:\\users\\sweet pea\\anaconda3\\lib\\site-packages (from scrapy>=2.5.0->advertools) (3.4.8)\n",
      "Requirement already satisfied: zope.interface>=4.1.3 in c:\\users\\sweet pea\\anaconda3\\lib\\site-packages (from scrapy>=2.5.0->advertools) (5.4.0)\n",
      "Requirement already satisfied: parsel>=1.5.0 in c:\\users\\sweet pea\\anaconda3\\lib\\site-packages (from scrapy>=2.5.0->advertools) (1.6.0)\n",
      "Requirement already satisfied: PyDispatcher>=2.0.5 in c:\\users\\sweet pea\\anaconda3\\lib\\site-packages (from scrapy>=2.5.0->advertools) (2.0.5)\n",
      "Requirement already satisfied: Twisted>=17.9.0 in c:\\users\\sweet pea\\anaconda3\\lib\\site-packages (from scrapy>=2.5.0->advertools) (22.2.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\sweet pea\\anaconda3\\lib\\site-packages (from cryptography>=2.0->scrapy>=2.5.0->advertools) (1.15.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\sweet pea\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=2.0->scrapy>=2.5.0->advertools) (2.21)\n",
      "Requirement already satisfied: jmespath>=0.9.5 in c:\\users\\sweet pea\\anaconda3\\lib\\site-packages (from itemloaders>=1.0.1->scrapy>=2.5.0->advertools) (0.10.0)\n",
      "Requirement already satisfied: pyasn1-modules in c:\\users\\sweet pea\\anaconda3\\lib\\site-packages (from service-identity>=16.0.0->scrapy>=2.5.0->advertools) (0.2.8)\n",
      "Requirement already satisfied: attrs>=16.0.0 in c:\\users\\sweet pea\\anaconda3\\lib\\site-packages (from service-identity>=16.0.0->scrapy>=2.5.0->advertools) (21.4.0)\n",
      "Requirement already satisfied: constantly>=15.1 in c:\\users\\sweet pea\\anaconda3\\lib\\site-packages (from Twisted>=17.9.0->scrapy>=2.5.0->advertools) (15.1.0)\n",
      "Requirement already satisfied: incremental>=21.3.0 in c:\\users\\sweet pea\\anaconda3\\lib\\site-packages (from Twisted>=17.9.0->scrapy>=2.5.0->advertools) (21.3.0)\n",
      "Requirement already satisfied: hyperlink>=17.1.1 in c:\\users\\sweet pea\\anaconda3\\lib\\site-packages (from Twisted>=17.9.0->scrapy>=2.5.0->advertools) (21.0.0)\n",
      "Requirement already satisfied: twisted-iocpsupport<2,>=1.0.2 in c:\\users\\sweet pea\\anaconda3\\lib\\site-packages (from Twisted>=17.9.0->scrapy>=2.5.0->advertools) (1.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in c:\\users\\sweet pea\\anaconda3\\lib\\site-packages (from Twisted>=17.9.0->scrapy>=2.5.0->advertools) (4.1.1)\n",
      "Requirement already satisfied: Automat>=0.8.0 in c:\\users\\sweet pea\\anaconda3\\lib\\site-packages (from Twisted>=17.9.0->scrapy>=2.5.0->advertools) (20.2.0)\n",
      "Requirement already satisfied: idna>=2.5 in c:\\users\\sweet pea\\anaconda3\\lib\\site-packages (from hyperlink>=17.1.1->Twisted>=17.9.0->scrapy>=2.5.0->advertools) (3.3)\n",
      "Requirement already satisfied: requests>=2.1.0 in c:\\users\\sweet pea\\anaconda3\\lib\\site-packages (from twython>=3.8.0->advertools) (2.27.1)\n",
      "Collecting requests-oauthlib>=0.4.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\sweet pea\\anaconda3\\lib\\site-packages (from requests>=2.1.0->twython>=3.8.0->advertools) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sweet pea\\anaconda3\\lib\\site-packages (from requests>=2.1.0->twython>=3.8.0->advertools) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sweet pea\\anaconda3\\lib\\site-packages (from requests>=2.1.0->twython>=3.8.0->advertools) (1.26.9)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Requirement already satisfied: filelock>=3.0.8 in c:\\users\\sweet pea\\anaconda3\\lib\\site-packages (from tldextract->scrapy>=2.5.0->advertools) (3.6.0)\n",
      "Requirement already satisfied: requests-file>=1.4 in c:\\users\\sweet pea\\anaconda3\\lib\\site-packages (from tldextract->scrapy>=2.5.0->advertools) (1.5.1)\n",
      "Installing collected packages: oauthlib, requests-oauthlib, twython, pyarrow, advertools\n",
      "Successfully installed advertools-0.13.2 oauthlib-3.2.2 pyarrow-10.0.1 requests-oauthlib-1.3.1 twython-3.9.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install advertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acd2149",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
